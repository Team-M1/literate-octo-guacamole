{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A2pUAeYufNo",
        "outputId": "20cb8624-c975-45ee-d78e-8e9329b82d73"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 18 16:18:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    30W /  70W |   3160MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqEjSS6HF_co"
      },
      "source": [
        "# **악플 탐지기 모델**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJN8tTRrGAdK"
      },
      "source": [
        "## **파이썬 패키치 설치 및 가져오기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUtJXAbdGYbi"
      },
      "source": [
        "### **git clone**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xamxDOAwEG0d",
        "outputId": "89130337-80d9-4a7c-e80e-0676976ca6ef"
      },
      "source": [
        "# https://github.com/monologg/KoCharELECTRA\n",
        "!git clone https://github.com/monologg/KoCharELECTRA\n",
        "\n",
        "# 데이터셋만 가져옴\n",
        "!git clone https://github.com/Team-M1/preprocessing-for-final-project.git"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'KoCharELECTRA' already exists and is not an empty directory.\n",
            "Cloning into 'preprocessing-for-final-project'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 85 (delta 37), reused 52 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7vhAlFtGaCd"
      },
      "source": [
        "### **pip install**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udLqQ4nbEIN9",
        "outputId": "0bfd8173-ecb2-40bb-fe83-0f526f669cad"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Di16BWGe7t"
      },
      "source": [
        "### **import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTgDWbdkE7BO"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import Trainer, TrainingArguments, ElectraModel\n",
        "\n",
        "from KoCharELECTRA.tokenization_kocharelectra import KoCharElectraTokenizer"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckK4bZyLGC5a"
      },
      "source": [
        "## **기본 설정값**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noEm2gD0HaQi"
      },
      "source": [
        "### **데이터셋**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKOHNoWiJ-Sl"
      },
      "source": [
        "data_path = \"preprocessing-for-final-project/data/혐오표현_정제.csv\""
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dLFMa97uMeui",
        "outputId": "e774bffb-d90c-45bd-95e9-0f78eccf827f"
      },
      "source": [
        "df = pd.read_csv(data_path)\n",
        "df.head()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>hate</th>\n",
              "      <th>gender_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>걍 이 병신나라 민도가 좆박은건데 어쩔수가 잇나 걍 망해야지</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>그 앰생 쓰레기 병신들은 짐승이고. 니는 짐승을 사람 취급해주냐.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>제발 너그집으로 꺼져 애미뒤진새끼야</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>몸만지면 대주는 걸레년임</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>환경오염도 이쯤되면 심각하고 자식 낳아봐야 지들 애미애비(그러므로 너 나 우리)가 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  hate  gender_hate\n",
              "0                  걍 이 병신나라 민도가 좆박은건데 어쩔수가 잇나 걍 망해야지     1            0\n",
              "1               그 앰생 쓰레기 병신들은 짐승이고. 니는 짐승을 사람 취급해주냐.     1            0\n",
              "2                                제발 너그집으로 꺼져 애미뒤진새끼야     1            0\n",
              "3                                      몸만지면 대주는 걸레년임     1            1\n",
              "4  환경오염도 이쯤되면 심각하고 자식 낳아봐야 지들 애미애비(그러므로 너 나 우리)가 ...     1            0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbypD0PLehTe"
      },
      "source": [
        "X, y = df[\"content\"].to_list(), df[\"gender_hate\"].to_list()"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKyTWi6uHYg8"
      },
      "source": [
        "### **토크나이저**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPPRKD_HDKNg",
        "outputId": "ebddfef9-4aad-4f19-8e26-24606db13c70"
      },
      "source": [
        "tokenizer = KoCharElectraTokenizer.from_pretrained(\"monologg/kocharelectra-base-discriminator\")\n",
        "print(tokenizer.tokenize('안녕하세요 제 이름은 김이라고 해요.'))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \n",
            "The class this function is called from is 'KoCharElectraTokenizer'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['안', '녕', '하', '세', '요', ' ', '제', ' ', '이', '름', '은', ' ', '김', '이', '라', '고', ' ', '해', '요', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5w5ITQVHSuX"
      },
      "source": [
        "### **전이학습할 모델**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7DZPyCeH4x9",
        "outputId": "b84747f5-00bf-4168-853e-c0467f1f694d"
      },
      "source": [
        "pretrained_model = ElectraModel.from_pretrained(\"monologg/kocharelectra-base-discriminator\")"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at monologg/kocharelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5HEBsz-HdeF"
      },
      "source": [
        "### **기타 (시드 등)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPHDfzuNJ2a8"
      },
      "source": [
        "seed = 1234\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEYDDE6TKtig"
      },
      "source": [
        "## **데이터 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8ytnXu9N-fn"
      },
      "source": [
        "### **Random Over Sampling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aP1VbDgz446"
      },
      "source": [
        "https://imbalanced-learn.org/stable/over_sampling.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o1Q5v9Lu-Z9",
        "outputId": "50986473-5811-4eac-fe60-1778615c9a3b"
      },
      "source": [
        "print(\"gender_hate 0:\", y.count(0))\n",
        "print(\"gender_hate 1:\", y.count(1))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender_hate 0: 7735\n",
            "gender_hate 1: 1007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbcHl0iLPBmH",
        "outputId": "48edaf2c-520d-41c9-8385-147cc4c2d699"
      },
      "source": [
        "ros = RandomOverSampler(random_state=seed)\n",
        "X, y = ros.fit_resample(np.asarray(X).reshape(-1, 1), np.asarray(y).reshape(-1, 1))\n",
        "X, y = list(map(lambda x: x[0], X.tolist())), y.tolist()\n",
        "print(\"gender_hate 0:\", y.count(0))\n",
        "print(\"gender_hate 1:\", y.count(1))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender_hate 0: 7735\n",
            "gender_hate 1: 7735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMX4vZ--PVI9"
      },
      "source": [
        "### **SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaWKYgdaPplV"
      },
      "source": [
        "# https://wyatt37.tistory.com/10"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKGPkwNLPpYe"
      },
      "source": [
        "### **Borderline-SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IlO7K_9PW_3"
      },
      "source": [
        "# https://datascienceschool.net/03%20machine%20learning/14.02%20%EB%B9%84%EB%8C%80%EC%B9%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AC%B8%EC%A0%9C.html"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccHPshD3PjHf"
      },
      "source": [
        "### **ADASYN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVDhbNROPhg5"
      },
      "source": [
        "# https://wyatt37.tistory.com/10"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIWTQmtMzTev"
      },
      "source": [
        "## **데이터 준비**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFAuuwyNXjzd"
      },
      "source": [
        "### **Text Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4GHwPRJaWcR",
        "outputId": "4c3b5a9f-d095-4e1a-8c82-bbf0b6904e72"
      },
      "source": [
        "X_encoding = tokenizer(X, padding=True)[\"input_ids\"]\n",
        "print(\"Encoding:\", np.array(X_encoding).shape)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoding: (15470, 172)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqdaAf3rRxbV"
      },
      "source": [
        "### **Train, Val, Test 데이터셋 분리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEp3x_3MR3xv"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_encoding, y, test_size=0.1, random_state=seed)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UflnElPPSZVK",
        "outputId": "7f18e434-18db-4d28-eb62-32a8db491145"
      },
      "source": [
        "print(\"Training:\", np.array(X_train).shape, \",\", np.array(y_train).shape)\n",
        "print(\"Validation:\", np.array(X_val).shape, \",\", np.array(y_val).shape)\n",
        "print(\"Test:\", np.array(X_test).shape, \",\", np.array(y_test).shape)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: (12530, 172) , (12530,)\n",
            "Validation: (1393, 172) , (1393,)\n",
            "Test: (1547, 172) , (1547,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddZckH6cUhZP"
      },
      "source": [
        "### **TensorDataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6ziMnGJUg0H"
      },
      "source": [
        "train_dataset = TensorDataset(torch.LongTensor(X_train), torch.LongTensor(y_train))\n",
        "val_dataset = TensorDataset(torch.LongTensor(X_val), torch.LongTensor(y_val))\n",
        "test_dataset = TensorDataset(torch.LongTensor(X_test), torch.LongTensor(y_test))"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDL5TZjbUfjM"
      },
      "source": [
        "### **DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wSyuO2dSlrI"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=2, pin_memory = True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, shuffle=True, batch_size=batch_size, num_workers=2, pin_memory = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=batch_size, num_workers=2, pin_memory = True)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJlOuSMirA3j"
      },
      "source": [
        "## **모델 학습하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXE3S07Ij-XV"
      },
      "source": [
        "### **GRU 모델**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGAq6oEsXM2w"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GRUNet(nn.Module):\n",
        "    def __init__(self, pretrained, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        self.pretrained = pretrained\n",
        "        embedding_dim = pretrained.config.to_dict()['hidden_size']\n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        #text = [batch size, sent len]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedded = self.pretrained(text)[0]\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        #output = [batch size, out dim]\n",
        "        return output"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poYheJ1yj0ax"
      },
      "source": [
        "### **학습을 위한 유틸 함수**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWXbp3ZvYPGC"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIz3jzF_XhsN"
      },
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "\n",
        "    for data, label in dataloader:\n",
        "        data = data.cuda()\n",
        "        label = label.float().cuda()\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(data).squeeze(1)\n",
        "        loss = criterion(predictions, label)\n",
        "        acc = binary_accuracy(predictions, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuBUai-UXnJW"
      },
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, label in dataloader:\n",
        "            data = data.cuda()\n",
        "            label = label.float().cuda()\n",
        "            predictions = model(data).squeeze(1)\n",
        "            loss = criterion(predictions, label)\n",
        "            acc = binary_accuracy(predictions, label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZXbh5wXXroZ"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM8n_G6MkJrc"
      },
      "source": [
        "### **학습하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Yk2qEjkQxA"
      },
      "source": [
        "hidden_dim = 256\n",
        "output_dim = 1\n",
        "n_layers = 2\n",
        "bidirectional = True\n",
        "dropout = 0.2\n",
        "\n",
        "epochs = 20\n",
        "best_valid_loss = float('inf')"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joqE2L5ccZJW",
        "outputId": "0e4ba9c4-dc9c-43bc-de67-60f62471d194"
      },
      "source": [
        "model = GRUNet(pretrained_model, hidden_dim, output_dim, n_layers, bidirectional, dropout).cuda()\n",
        "\n",
        "# 전이학습 모델 가중치 고정\n",
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('pretrained'):\n",
        "        param.requires_grad = False\n",
        "print(\"Model parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model parameters: 2759169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FKF0lKDXYzJ"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZdjjuVaXtUw",
        "outputId": "27547fc1-2162-432a-816c-885c18b0057d"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_loader, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 2m 43s\n",
            "\tTrain Loss: 0.534 | Train Acc: 73.04%\n",
            "\t Val. Loss: 0.406 |  Val. Acc: 81.67%\n",
            "Epoch: 02 | Epoch Time: 2m 55s\n",
            "\tTrain Loss: 0.358 | Train Acc: 84.82%\n",
            "\t Val. Loss: 0.238 |  Val. Acc: 90.77%\n",
            "Epoch: 03 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.237 | Train Acc: 90.57%\n",
            "\t Val. Loss: 0.215 |  Val. Acc: 92.24%\n",
            "Epoch: 04 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.148 | Train Acc: 94.34%\n",
            "\t Val. Loss: 0.145 |  Val. Acc: 94.96%\n",
            "Epoch: 05 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.102 | Train Acc: 96.18%\n",
            "\t Val. Loss: 0.172 |  Val. Acc: 93.85%\n",
            "Epoch: 06 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.078 | Train Acc: 97.17%\n",
            "\t Val. Loss: 0.118 |  Val. Acc: 96.57%\n",
            "Epoch: 07 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.052 | Train Acc: 98.00%\n",
            "\t Val. Loss: 0.100 |  Val. Acc: 97.02%\n",
            "Epoch: 08 | Epoch Time: 2m 55s\n",
            "\tTrain Loss: 0.045 | Train Acc: 98.31%\n",
            "\t Val. Loss: 0.110 |  Val. Acc: 96.71%\n",
            "Epoch: 09 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.040 | Train Acc: 98.54%\n",
            "\t Val. Loss: 0.126 |  Val. Acc: 96.62%\n",
            "Epoch: 10 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.030 | Train Acc: 98.96%\n",
            "\t Val. Loss: 0.135 |  Val. Acc: 96.48%\n",
            "Epoch: 11 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.039 | Train Acc: 98.63%\n",
            "\t Val. Loss: 0.083 |  Val. Acc: 97.26%\n",
            "Epoch: 12 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.027 | Train Acc: 98.95%\n",
            "\t Val. Loss: 0.100 |  Val. Acc: 97.30%\n",
            "Epoch: 13 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.26%\n",
            "\t Val. Loss: 0.078 |  Val. Acc: 98.13%\n",
            "Epoch: 14 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.022 | Train Acc: 99.23%\n",
            "\t Val. Loss: 0.057 |  Val. Acc: 98.86%\n",
            "Epoch: 15 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.022 | Train Acc: 99.26%\n",
            "\t Val. Loss: 0.070 |  Val. Acc: 98.22%\n",
            "Epoch: 16 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.23%\n",
            "\t Val. Loss: 0.083 |  Val. Acc: 97.80%\n",
            "Epoch: 17 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.37%\n",
            "\t Val. Loss: 0.138 |  Val. Acc: 97.07%\n",
            "Epoch: 18 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.32%\n",
            "\t Val. Loss: 0.098 |  Val. Acc: 98.01%\n",
            "Epoch: 19 | Epoch Time: 2m 57s\n",
            "\tTrain Loss: 0.020 | Train Acc: 99.27%\n",
            "\t Val. Loss: 0.157 |  Val. Acc: 96.50%\n",
            "Epoch: 20 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.51%\n",
            "\t Val. Loss: 0.101 |  Val. Acc: 97.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnaZmX0ijh0H"
      },
      "source": [
        "## **모델 최종 정확도 측정하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB9xoka8jpZw",
        "outputId": "0ba74b49-2017-4751-fd31-00e8ff645f6f"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.056 | Test Acc: 98.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCuefmyZETTV"
      },
      "source": [
        "## **데이터 추론하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOuPYygFKf0k"
      },
      "source": [
        "### **kocohub unlabeled 데이터**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_KMyBf2Fy3E",
        "outputId": "8f795bd1-c0aa-4d8d-ccef-93ecde13c6e6"
      },
      "source": [
        "!git clone https://github.com/kocohub/korean-hate-speech"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'korean-hate-speech'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 112 (delta 4), reused 0 (delta 0), pack-reused 103\u001b[K\n",
            "Receiving objects: 100% (112/112), 93.18 MiB | 20.89 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Checking out files: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2syNoQqJF-xl"
      },
      "source": [
        "unlabeled_path = \"korean-hate-speech/unlabeled/unlabeled_comments_1.txt\""
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "mXFmHnD1EklQ",
        "outputId": "dbff5f54-875a-4542-fd9d-9f47d3f5116d"
      },
      "source": [
        "df_unlabeled = pd.read_csv(unlabeled_path, sep=\"\\n\")\n",
        "df_unlabeled.head()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>지드래곤은 난봉꾼이란...댓글도 달렸네 ㅋㅋ 이주연 학창시절 사진 보고 와라. 요즘 웬만한 여자 연예인하고 붙여놔도....미모가 최고였단다.ㅋ 5대 얼짱 출신.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>이주연은 알겠는데 지디는 뭐하는 듣보잡여</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>부럽네요. 나도 불과 한달전까진 허니문베이비를 꿈꿨는데 이제 다 부질없네요. 당연히...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이주연을 모르는 애들이 많네. 해체된 애프터스쿨 멤버로 당시는 주연이 예명. 인기나...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>겨론했으면</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>이주연이 아깝다 진심</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  지드래곤은 난봉꾼이란...댓글도 달렸네 ㅋㅋ 이주연 학창시절 사진 보고 와라. 요즘 웬만한 여자 연예인하고 붙여놔도....미모가 최고였단다.ㅋ 5대 얼짱 출신.\n",
              "0                             이주연은 알겠는데 지디는 뭐하는 듣보잡여                                       \n",
              "1  부럽네요. 나도 불과 한달전까진 허니문베이비를 꿈꿨는데 이제 다 부질없네요. 당연히...                                       \n",
              "2  이주연을 모르는 애들이 많네. 해체된 애프터스쿨 멤버로 당시는 주연이 예명. 인기나...                                       \n",
              "3                                              겨론했으면                                       \n",
              "4                                        이주연이 아깝다 진심                                       "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmNjfPUdGbWU"
      },
      "source": [
        "max_input_length = 172\n",
        "\n",
        "def predict_sentiment(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    tensor = torch.LongTensor(indexed).cuda()\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ3C9wIdGv88",
        "outputId": "c1368408-67c8-4ffa-a51d-05bb267a3202"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"안녕하세용\")\n"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01115437038242817"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3LSIR-dHClw",
        "outputId": "8963bb16-6d5a-40de-a073-bd0d8d58d8df"
      },
      "source": [
        "count = 50\n",
        "\n",
        "with open(unlabeled_path, \"r\") as f:\n",
        "  while True:\n",
        "    if count < 0: break\n",
        "    count -= 1\n",
        "    line = f.readline()\n",
        "    print(line, end=\"\")\n",
        "    print(predict_sentiment(model, tokenizer, line))\n",
        "    print(\"==========\")"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "지드래곤은 난봉꾼이란...댓글도 달렸네 ㅋㅋ 이주연 학창시절 사진 보고 와라. 요즘 웬만한 여자 연예인하고 붙여놔도....미모가 최고였단다.ㅋ 5대 얼짱 출신.\n",
            "0.9995729327201843\n",
            "==========\n",
            "이주연은 알겠는데 지디는 뭐하는 듣보잡여\n",
            "0.6350446939468384\n",
            "==========\n",
            "부럽네요. 나도 불과 한달전까진 허니문베이비를 꿈꿨는데 이제 다 부질없네요. 당연히 순결할거라 믿었고 그래서 첫날밤까지 기다려준건데 배신감만 듭니다. 첫날밤 와이프가 피를 안흘렸어요. 처가집식구들이 일부러 절 속였단 생각에 화도나고 어제 처가집가기로 했는데 안간다고 했더니 혼자 울고 갔다와서 지금까지 한마디도 안해요. 이혼하고 싶네요\n",
            "0.0005666663637384772\n",
            "==========\n",
            "이주연을 모르는 애들이 많네. 해체된 애프터스쿨 멤버로 당시는 주연이 예명. 인기나 포텐은 안터졌으나, 순수미모만으로는 애프터스쿨에서 원탑이었다. 진짜 자연미인이다.\n",
            "0.00011339018237777054\n",
            "==========\n",
            "겨론했으면\n",
            "0.2412661761045456\n",
            "==========\n",
            "이주연이 아깝다 진심\n",
            "0.000891237985342741\n",
            "==========\n",
            "방탄은 건드리지말자 인간적으로.. 해외활동 지금주터 시작인데 터지면 진짜 전 세계적으로 활짝 피기도 전에 난리난다.. 국위선양하는 떠오르는 샛별은 제발 건드리지말고.. 탄이들도 만약 연애하더라도 들키지 않길.. ㅠㅠ\n",
            "5.655345739796758e-05\n",
            "==========\n",
            "선남선녀의 만남이네요^^\n",
            "0.06127695366740227\n",
            "==========\n",
            "문재앙 또뭘덥고 싶어서 ㄷㄷㄷ\n",
            "0.0007025920785963535\n",
            "==========\n",
            "주연이 아깝긴해요\n",
            "0.00017643717001192272\n",
            "==========\n",
            "지디는 아이유랑 너무 잘 어울리는데. 아쉽당~마지막은 아이유랑 해 주세요~ 인류의 축복을 위해서^^\n",
            "0.001114502432756126\n",
            "==========\n",
            "오빠 좀 괴롭지 마요\n",
            "0.7519452571868896\n",
            "==========\n",
            "너희 실수했어 사람 잘못골랐어 이거 오보야\n",
            "0.0005156744737178087\n",
            "==========\n",
            "모두가 거짓기사임..같이 찍은 사진도 없고 지디가 아니라고 분명히 못을 박았음..집근처 사진은 나도 하겠다..구하라 설리도 연합했니? 사진보니 친구인거 같던데? 여기서 왜나와? 이제 안되니까 치밀하게 계획해서 몰아가기 알바쓰고 제대로 한건 크게 관종짓을 했네..ㅉㅉ..알바들이나 믿지..대중은 안 믿어...스쳐간 인연 스토커짓 이제 접어라...제발~~~\n",
            "0.0003354937070980668\n",
            "==========\n",
            "문재앙이 발악하고 있네\n",
            "0.442168653011322\n",
            "==========\n",
            "매력적이네 친구가 참 여자여자네\n",
            "0.020013956353068352\n",
            "==========\n",
            "이주연 진짜 예쁘긴함 ㅇㅇ\n",
            "0.25196534395217896\n",
            "==========\n",
            "솔직히 사귀던가 말던가 상관없지만 사실만 말하면 저날 승리가 펜션에 놀러간걸로 알고있는데..? 단둘이서 노는데 눈치없이 펜션에 놀러갔을까? 게다가 지디보다 매니져랑 찍힌 사진이 더 많은걸보니 매니져랑 사귀는거 아님?\n",
            "0.030863752588629723\n",
            "==========\n",
            "주연이는 구혜선,박한별과 함께....5대 얼짱이었는데...무슨 급이 안맞다고 지롤떠냐?? 악플다는 니들 지드래곤 빠순이들은....거울도 안보냐?? 니가 더 이뻐??? 양심껏 대답해봐 ㅋㅋㅋ\n",
            "8.862245886120945e-05\n",
            "==========\n",
            "모두가 거짓기사임..같이 찍은 사진도 없고 지디가 아니라고 분명히 못을 박았음..집근처 사진은 나도 하겠다..구하라 설리도 연합했니? 사진보니 친구인거 같던데? 여기서 왜나와? 이제 안되니까 치밀하게 계획해서 몰아가기 알바쓰고 제대로 한건 크게 관종짓을 했네..ㅉㅉ..알바들이나 믿지..대중은 안 믿어..완전 스토커 여자라도 소름끼친다.\n",
            "0.0003354937070980668\n",
            "==========\n",
            "모두가 거짓기사임..같이 찍은 사진도 없고 지디가 아니라고 분명히 못을 박았음..집근처 사진은 나도 하겠다.. 이제 안되니까 치밀하게 계획해서 몰아가기 알바쓰고 제대로 한건 크게 관종짓을 했네..ㅉㅉ..알바들이나 믿지..대중은 안 믿어...스쳐간 인연이니 이제는 스토커 그만해 ...제발~~~지디 이주연 고소해라..허위 날조 기사\n",
            "0.0003093745617661625\n",
            "==========\n",
            "모두가 거짓기사임..같이 찍은 사진도 없고 지디가 아니라고 분명히 못을 박았음..집근처 사진은 나도 하겠다.. 이제 안되니까 치밀하게 계획해서 몰아가기 알바쓰고 제대로 한건 크게 관종짓을 했네..ㅉㅉ..알바들이나 믿지..대중은 안 믿어...스쳐간 인연이니 이제는 스토커 그만해 ...제발~~~지디 이주연 고소해라..허위 날조 기사\n",
            "0.0003093745617661625\n",
            "==========\n",
            "지디가 아이유도 건드리지 않았을까? 아이유가 안넘어왔을듯\n",
            "0.000901934748981148\n",
            "==========\n",
            "이주연 이보크 타이어만도 못한녀들이 급이 어떻고 사람보는눈이 없네 마네하는걸 보니 기가 차다 기가차 ㅋㅋㅋ 콩깍지좀 벗고 주제파악 좀 하자\n",
            "0.006750147324055433\n",
            "==========\n",
            "뭘 실망이야 OOO아 지드래곤 안사귀는 줄 알았잖아 빠순이들아ㅋㅋㅋㅋ\n",
            "0.008047521114349365\n",
            "==========\n",
            "여자들이 주연이 너무 깐다.ㅋㅋㅋ~ 아무리 지디빠라지만 같은 여자끼리 감싸줘라 ㅎㅎ\n",
            "0.18312685191631317\n",
            "==========\n",
            "둘이 좋아서 사귄다는데 급 매기는 사람들 웰케 많냐.. 그렇다고 저 정도 외모에 돈 이상으로 가진 것도 아니면서\n",
            "0.008470248430967331\n",
            "==========\n",
            "새해부터 이주연 깎아 내리느라 수고한다. 이주연 발톱 때보다 못생긴 오크 쿵쾅녀들아 ㅋㅋㅋ\n",
            "0.9999630451202393\n",
            "==========\n",
            "이주연님 성격 진짜 좋아보이던데 ! 예쁜연애 하시길 바래요 ❤️\n",
            "0.00011201683810213581\n",
            "==========\n",
            "이준 정소미기사는 사실/ 지디 이주연 기사는 거짓...사진도 글도 너무 비교되고..이주연이 관종짓을 이번엔 크게 하고 있음...모두 믿지 마세요..거짓말임..이젠 발목잡기 틀렸으니까 복수하는 것임..이게 팩트임..아주 가지가지 하고있음..구하라 설리도 연합했나? 글에 이름이..저번에 같이 사진도 찍고 친구인가 본데..\n",
            "0.039652109146118164\n",
            "==========\n",
            "문재인정부가 뭘 덮으려고 이주연에 정소민까지 빵빵 터트리네요 하지만 깨시민들은 이런 저질스러운 연예인 돌려막기에 현혹되지 않습니다!!! 무한rt!!!!\n",
            "2.9020577130722813e-05\n",
            "==========\n",
            "새해 첫날부터 문재인정부는 뭘 덮으려고 이런 기사를 터뜨린거죠?\n",
            "0.0001317739370279014\n",
            "==========\n",
            "산불재앙 또 감추려고 열애설 터뜨렸네;; 하여간에 이 정부는... 어휴.. 답이 없다 답이 없어;;;\n",
            "7.558031211374328e-05\n",
            "==========\n",
            "이주연님 되게 이쁘시다 오빠 오래가요 잘어울려 주연님 울오빠 잘부탁해요\n",
            "0.0001642989955144003\n",
            "==========\n",
            "이주연 이쁜데왜~~~ 결혼까지해라 태양처럼\n",
            "0.00038627273170277476\n",
            "==========\n",
            "지디 실망이네.. 개념 스시녀만 사귀는줄 알았는데 김치녀 사귀노..\n",
            "0.03147125989198685\n",
            "==========\n",
            "어울령.주연씨도 길고 세련된 느낌이라 ~~2세는 큰 지디면 대박일듯\n",
            "0.007250133436173201\n",
            "==========\n",
            "우리지용이는 그누구랑 사귀어도 이지랄들일꺼야ㅠㅠ\n",
            "0.0009282999089919031\n",
            "==========\n",
            "지드래곤 이쁜여자 잡았으니까 땡잡았다고 본다.\n",
            "0.9472220540046692\n",
            "==========\n",
            "지디마약사건으로 사람들이 욕하는데 마약이 솔직히 왜 나쁜거냐고 물으면 다들 아무도 대답못함. 내 미국인친구도 코카인흡입이 나쁘다고 하길래 그게 왜 나쁘냐고 물으니까 그냥 나쁘지.. 사람의 정신을 몽롱하게 만들고... 이렇게 말함.. 결국 명쾌한 답변을 아무도 못해. 지디야 힘내렴! 여기가 북한이냐? 대마초하건말건 뭔상관이냐\n",
            "4.6788438339717686e-05\n",
            "==========\n",
            "정부가 뭘 또 숨길려고 새해부터 열애설 터트릴까요?\n",
            "0.00038263556780293584\n",
            "==========\n",
            "헐 디패 대박ㄷㄷㄷ\n",
            "0.02610008977353573\n",
            "==========\n",
            "진짜 연인관계가 맞다면 예쁜사랑하세요~응원하겠습니다:)\n",
            "0.0002865165297407657\n",
            "==========\n",
            "지디 부럽다 ...모든 20대 여자 다 만날 능력돼서 ㅋㅋㅋ\n",
            "0.95677649974823\n",
            "==========\n",
            "성공하려면 아랫도리 마구 굴려야지 ㅋㅋ\n",
            "0.027351489290595055\n",
            "==========\n",
            "그지근성인 여자 안 만나서 다행\n",
            "0.9007949829101562\n",
            "==========\n",
            "관심없고 지디의 블랙카드가 아까울뿐이다ㅋ\n",
            "0.0010786589700728655\n",
            "==========\n",
            "우리 뷔오빠가 더 낳다\n",
            "0.003258166601881385\n",
            "==========\n",
            "어리고 이쁘고 가슴큰 여자들 널렸고... 지디 정도면 아무나 골라서 사귈 수 있을텐데... 왜 연상에... 심지어 자기보다 키도 큰 여자를 만나는 건지...\n",
            "0.5680772662162781\n",
            "==========\n",
            "모두가 거짓기사임..같이 찍은 사진도 없고 지디가 아니라고 분명히 못을 박았음..집근처 사진은 나도 하겠다..구하라 설리도 연합했니? 사진보니 친구인거 같던데? 여기서 왜나와? 이제 안되니까 치밀하게 계획해서 몰아가기 알바쓰고 제대로 한건 크게 관종짓을 했네..ㅉㅉ..알바들이나 믿지..대중은 안 믿어...스쳐간 인연이니 이제는 스토커 그만해 ...제발~~~\n",
            "0.0003354937070980668\n",
            "==========\n",
            "새해부터 개 10같은 소리하지마라. 기자쉐이야.....개소리 왈왈하다간 주둥이 짖쪄버린다.\n",
            "0.0029026346746832132\n",
            "==========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWp5-JGELwXo",
        "outputId": "e19fa884-8f86-4f3b-b635-89014bac4f07"
      },
      "source": [
        "count = 50\n",
        "\n",
        "with open(unlabeled_path, \"r\") as f:\n",
        "  line = f.readline()\n",
        "  while True:\n",
        "    if count < 0: break\n",
        "    line = f.readline()\n",
        "\n",
        "    sent = predict_sentiment(model, tokenizer, line)\n",
        "    if sent > 0.95:\n",
        "      count -= 1\n",
        "      print(line, end=\"\")\n",
        "      print(predict_sentiment(model, tokenizer, line))\n",
        "      print(\"==========\")"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "새해부터 이주연 깎아 내리느라 수고한다. 이주연 발톱 때보다 못생긴 오크 쿵쾅녀들아 ㅋㅋㅋ\n",
            "0.9999630451202393\n",
            "==========\n",
            "지디 부럽다 ...모든 20대 여자 다 만날 능력돼서 ㅋㅋㅋ\n",
            "0.95677649974823\n",
            "==========\n",
            "정치, 과학, 사회 관련 기사의 댓글과 관심도 남자95% 여자 5%, 연예관련 기사의 댓글과 관심도 여자 70~90% ㅋㅋㅋㅋㅋㅋㅋ 실화냐? 이러니까 여자들 평균임금과 요직 비율이 낮지 ㅋㅋㅋ 근데 차별핑계 오지게 대더라 ㅋㅋ\n",
            "0.9991759657859802\n",
            "==========\n",
            "딱봐도 엔조이구만 ㅋ 남자색휘들은 잘 알듯~고대로 딱 그만큼 행동하네 ㅎㅎ\n",
            "0.9999023675918579\n",
            "==========\n",
            "주연이가 너무 아까워... 정말 예쁜데... 만날때 힐도 못신고 단화만 신어야될거 아니야... 남자가 170은 안되더라도 최소한 165는 넘어야지 ㅉㅉ...\n",
            "0.9981776475906372\n",
            "==========\n",
            "촛불들던 정신나간 놈\n",
            "0.992668628692627\n",
            "==========\n",
            "척척 찍 응애~\n",
            "0.9990543723106384\n",
            "==========\n",
            "연예계는 동물에왕국맞네 한낮조연 나부랭이가 연기는안하고 연기한답시고 여자나 꼬셔서 지 군대가는 욕구풀이로 한번씩 할려고 여자곰신 만들었네\n",
            "0.9891170859336853\n",
            "==========\n",
            "떡중이라 헤라\n",
            "0.992137610912323\n",
            "==========\n",
            "이아줌마는 뉴규??????????????\n",
            "0.9996505975723267\n",
            "==========\n",
            "준이 잘해?\n",
            "0.9802688956260681\n",
            "==========\n",
            "동물의 왕국에서 또 한쌍의 암수가..\n",
            "0.9607526659965515\n",
            "==========\n",
            "군대에서는 치마만 걸치면 여자 @@\n",
            "0.9990241527557373\n",
            "==========\n",
            "근대 쟤네 누구임?배우임?\n",
            "0.9500033259391785\n",
            "==========\n",
            "동물의 왕국이네 이년아\n",
            "0.9883915781974792\n",
            "==========\n",
            "군인이 휴가 중에 운전을 해도 되나?\n",
            "0.9993755221366882\n",
            "==========\n",
            "안가려도 되는데 오바는\n",
            "0.997747004032135\n",
            "==========\n",
            "여자라는건 그냥 단지 한두번 욕정의 물을 비우기 위한 도구에 지나지 않는데 왜 자꾸들 연애를 할까..? 연애를 해주지 않으면 눕힐수 없으니까? 아님 이 여자만에게 평생 뿌려주고 싶어서? 다 부질없는 순간적 감정이다.. 지금은 이 여자 아니면 죽을것 같아도 결국 말그래도 '지금' 뿐이다. 그리고 그 순간을 넘기면 어느덧 눈가에 주름이 늘어가는 늙어가는 퇴물의 모습만이 눈앞에 서서 나를 갉아먹으려 하는 퇴물만 남겠지.\n",
            "0.9676951766014099\n",
            "==========\n",
            "정소민바보...남자깔렷는데 군바리랑만나냐..\n",
            "0.9890284538269043\n",
            "==========\n",
            "응 지디 미만잡ㅋㅋ 왠 듣보잡들이여\n",
            "0.9993988275527954\n",
            "==========\n",
            "했을까? 했겠지?\n",
            "0.9674587845802307\n",
            "==========\n",
            "연예기사 댓글봐라 여자가 압도적 ㅋㅋ정치 경제는 아몰랑~~\n",
            "0.9899605512619019\n",
            "==========\n",
            "한녀들아 돈만 진짜 많으면 키 167 90키로 대머리에 배불뚝 남자도 섹시하지 않냐?ㅋㅋㅋ\n",
            "0.9995149374008179\n",
            "==========\n",
            "급낮다\n",
            "0.960260272026062\n",
            "==========\n",
            "머지 이건또\n",
            "0.9825302958488464\n",
            "==========\n",
            "이준 여자 좋아했었냐\n",
            "0.9976868629455566\n",
            "==========\n",
            "드디어 보상받는구나\n",
            "0.9588322639465332\n",
            "==========\n",
            "이서진 합류하자 ㅋㅋㅋㅋ\n",
            "0.9582170844078064\n",
            "==========\n",
            "불청 pd야 기존멤버 물갈이 좀 합시다 치와와 개커플 하차좀 어떻게 합시다 결혼해서 나갈일은 없을듯 김국진 결혼할 맘 아예 없어보여..한사람 이라도 하차좀 시킵시다\n",
            "0.9631816148757935\n",
            "==========\n",
            "18년 그냥 좌파는 다 꼽아주네ㅋ 18년\n",
            "0.953292727470398\n",
            "==========\n",
            "실검 ㅋㅋㅋㅋ1위 예약 ㅋㅋㅋㅋㅋㅋ\n",
            "0.9919677376747131\n",
            "==========\n",
            "형형 누나누나 하면서 앵알앵알 거리는거 거리는게 보기싫음\n",
            "0.989540159702301\n",
            "==========\n",
            "언제적 이하늘이여\n",
            "0.9942042231559753\n",
            "==========\n",
            "댓글봐라 ㅋㅋ 쿨한척 오지네 자기위로하는 지디 빠순이들 극혐\n",
            "0.999626636505127\n",
            "==========\n",
            "30대 상폐녀들 ㅂㄷㅂㄷ\n",
            "0.9996247291564941\n",
            "==========\n",
            "ㅈㄴ무섭네 ㅋㅋㅋ\n",
            "0.9993454813957214\n",
            "==========\n",
            "열애설 나면 악플러들이 물어뜯으니까 인정을 안하지 여기도 봐라 여자가 급이낮네 어쩌네 자기 여자친구가 저런 악플에 시달리는데 인정하고 싶겠냐? ㅋㅋ\n",
            "0.9935358762741089\n",
            "==========\n",
            "더큰거터뜨릴것ㅊ·럼하더니 고작얘네야?\n",
            "0.9758550524711609\n",
            "==========\n",
            "별거 아닌거 같은애가 지디사귀니까 눈꼴시려 죽겠지?ㅎㅋ\n",
            "0.9702229499816895\n",
            "==========\n",
            "지디 눈 별로안높네 그냥 시끄럽고 앵앵대는스타일좋아하는듯 .집에서 자고그담날나와서 제주도가서또3박4일ㅋㅋㅋ ㅋ 여자몸함부로굴리는거보소\n",
            "0.9869855046272278\n",
            "==========\n",
            "영화에 세뇌되는 ㅈㅂㅅ들. 김일성 교시가 생각난다. 에효.\n",
            "0.993036687374115\n",
            "==========\n",
            "강동원 체류탄맞을때 뒷자리 여자들 울었음\n",
            "0.9780929088592529\n",
            "==========\n",
            "혹시 작가가 1편은 어디서배끼고 이제 2편만드니까 뽀록나는거아녀어쩜이렇게 내용이 산으로가? 와오늘은 조폭두목이 불쌍해보이더라\n",
            "0.9743417501449585\n",
            "==========\n",
            "주진모가 여자들한테는 안먹히는얼굴이라던데 맞나요?\n",
            "0.9917540550231934\n",
            "==========\n",
            "난 재밌음 ㅋㅋ\n",
            "0.9853416681289673\n",
            "==========\n",
            "제일 웃긴건 엘베앞에서 총들이밀고 아가리전할때 ㅋㅋㅋㅋ 무슨 모임하니?\n",
            "0.995968222618103\n",
            "==========\n",
            "이래라 저래라 시애미질하지말고 쳐보질말자 그냥보는사람도있어 그냥 스토리어케해달라하지말고 시청률떨어지면 알아서들 알겠지 여튼 오지랖들은 ㅉㅉ\n",
            "0.9582487344741821\n",
            "==========\n",
            "두번째가 오지네\n",
            "0.9989684820175171\n",
            "==========\n",
            "몇년안에 김소현이 한국 최고 원탑 미녀 배우 된다. 장담한다\n",
            "0.9538230895996094\n",
            "==========\n",
            "얼굴 잘생겼다고 매국노 친일파도 감싸는 메갈들 ㅋㅋ\n",
            "0.954696536064148\n",
            "==========\n",
            "김치년들 강동원나올때 꺄악! ㅇㅈㄹ떨던데 영화관에서 기본적인 매너도없음ㅋㅋ 사회암적존재들ㅋㅋ\n",
            "0.9997877478599548\n",
            "==========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEI2ZfzrKjyy"
      },
      "source": [
        "### **황도원 데이터**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M6-B5Q2KYrw"
      },
      "source": [
        "unlabeled_path2 = \"preprocessing-for-final-project/unlabeled_data/concat_unlabeled_data.csv\""
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoMhibIRKeKC",
        "outputId": "15548618-3ad9-4a23-a9b1-7ed5267d494a"
      },
      "source": [
        "count = 50\n",
        "\n",
        "with open(unlabeled_path2, \"r\") as f:\n",
        "  line = f.readline()\n",
        "  while True:\n",
        "    if count < 0: break\n",
        "    count -= 1\n",
        "    line = f.readline()\n",
        "    print(line, end=\"\")\n",
        "    print(predict_sentiment(model, tokenizer, line))\n",
        "    print(\"==========\")"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "좌배 까는건 ㅇㅂ,1\n",
            "0.9953380823135376\n",
            "==========\n",
            "집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ,0\n",
            "0.1364128440618515\n",
            "==========\n",
            "개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아,1\n",
            "0.016883691772818565\n",
            "==========\n",
            "세탁이라고 봐도 된다,0\n",
            "0.005189033690840006\n",
            "==========\n",
            "애새끼가 초딩도 아니고 ㅋㅋㅋ,1\n",
            "0.6918653249740601\n",
            "==========\n",
            "731부대의 후예라 그런지 가학적인 아이디어는 세계최고임 이래서 애교만 떨어도 돈 벌리는 한국에 기를 써서 진출하려고 하지조센남자들은 또 이쁜여자만 보면 사족을 못쓰며 공주대접해주는 놈들이니,1\n",
            "0.962875485420227\n",
            "==========\n",
            "재앙이한건햇노,1\n",
            "0.9991575479507446\n",
            "==========\n",
            "글쓴이 와꾸 승리에 비하면 방사능 피폭 원숭이 일듯..,1\n",
            "0.06819329410791397\n",
            "==========\n",
            "마 씨발련 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나,1\n",
            "0.20083019137382507\n",
            "==========\n",
            "은행에 대출 상담 받으러 가보면 직업의 귀천 바로 알려줌,0\n",
            "0.0005461426917463541\n",
            "==========\n",
            "ㅋㅋㅋ,0\n",
            "0.39839810132980347\n",
            "==========\n",
            "ㄹㅇㅋㅋㅋ,0\n",
            "0.11311201751232147\n",
            "==========\n",
            "우리지역군데 금태섭 뽑으면 안되지? 그래도 자한당 뻡아야겠지?,0\n",
            "0.0026321723125874996\n",
            "==========\n",
            "꽃다발사들고 알바하는곳찾아가서 무릎꿇고 '내 마음을 받아줄래 지영아?' 하면 바로 넘어온다 여자들 이런거 존나좋아함,1\n",
            "0.30516284704208374\n",
            "==========\n",
            "박근혜 안빠는데 보수통합 3원칙 인정함,1\n",
            "0.0009512119577266276\n",
            "==========\n",
            "대가리에 필터없는 연봉 30억 강사vs대가리가 없는 용접공,1\n",
            "0.0033032523933798075\n",
            "==========\n",
            "백정주제에 라고하는걸 비하라고 느낀다면 본인조차 직업에 자부심이 없는건데,0\n",
            "0.020350849255919456\n",
            "==========\n",
            "이게 다 백인 탓이랑께,0\n",
            "0.07827646285295486\n",
            "==========\n",
            "뭐저런 골빈 ㄴ이 다있냐 ㅋㅋㅋ 저런게 학원강사라고? 애들이 불쌍,1\n",
            "0.08983074873685837\n",
            "==========\n",
            "마감시간 다돼서 떨이하는 고기 사먹으면 식중독 518퍼네아 오래 된 것도 새 거처럼 둔갑해서 다음날 팔테니 떨이라는 개념이 아예 없을라나,0\n",
            "0.03374818339943886\n",
            "==========\n",
            "열사발 들이켜도 아깝지 않음,0\n",
            "0.0021335252095013857\n",
            "==========\n",
            "정신병자 천국이구나,1\n",
            "0.07917958498001099\n",
            "==========\n",
            "으따 옷 이딴건 필요 없당깨 현금으로 달랑깨 !,0\n",
            "0.00018875696696341038\n",
            "==========\n",
            "난 사이트 마다 아이디/비번 다 다르고 난이도 높음엑셀 파일에 모든 아이디/비번 / 계좌정보 등등 다 들어 있고이 엑셀 파일에 비번만 기억함,0\n",
            "0.022749019786715508\n",
            "==========\n",
            "깍새들이 시발 존나강요하더라,1\n",
            "0.023449648171663284\n",
            "==========\n",
            "리뷰쓴 새끼가 쓰레기 맞지저건 ㅋㅋㅋ 존나 악랄하게 사진찍어 올리는데,1\n",
            "0.00024744559777900577\n",
            "==========\n",
            "ㅋㅋ ㅇㅈ 저런거에 앉아어 감전사 당할 수도,0\n",
            "0.9796949625015259\n",
            "==========\n",
            "틀딱 씨발새끼들아 다꺼져라 냄새나니까,1\n",
            "0.0036329650320112705\n",
            "==========\n",
            "근데 그것 요즘 살짝 트렌드 지났더라.,0\n",
            "0.0030553885735571384\n",
            "==========\n",
            "군대에서 여군이 필요한가,0\n",
            "0.992216944694519\n",
            "==========\n",
            "ㅋㅋ복수할겨,0\n",
            "0.8388122916221619\n",
            "==========\n",
            "내가 세금 안내면 너 같은 동사무소에서 프린트나 하는 새끼는 월급 못받고 굶어 뒈져야 돼 병신새끼야.,1\n",
            "0.004786395933479071\n",
            "==========\n",
            "면도 뭔 스머프모자 쓰고왓네,0\n",
            "0.8519087433815002\n",
            "==========\n",
            "사형 예지!,0\n",
            "0.999182403087616\n",
            "==========\n",
            "당연히 많이볼수밖에...,0\n",
            "0.000503038929309696\n",
            "==========\n",
            "흑종원 ㅋㅋㅋ,0\n",
            "0.9727607369422913\n",
            "==========\n",
            "=> 난 그런 말 한 적 없는데? ㅋㅋㅋㅎㅎㅋㅋㅋ왜 거짓말하노? ㅋㅋㅋ,0\n",
            "0.004913633689284325\n",
            "==========\n",
            "원래 수준이 그래,1\n",
            "0.013553476892411709\n",
            "==========\n",
            "호주에서는 남자들이 동물보다 못한존재라던데ㅋㅋ,0\n",
            "0.9981912970542908\n",
            "==========\n",
            "나베가 나베했네요!,0\n",
            "0.6365843415260315\n",
            "==========\n",
            "전에 제주도 여행 갔는데 폭포 앞에 사진 잘나오는 포토존에서 사진 찍는거 기다렸는데 앞의 6명의 짱게이 때문에 짜증남먼저 6명 각자 한장씩 찍음다음 번갈아 가면서 둘이나 셋이서 짝 지어서 찍음 정말 끝나서 싶어 찍을려고 하니 그 6명이 다 모여서 포즈 바꿔가면서 또 사진 찍음이지랄 하고 있음,1\n",
            "0.00040035188430920243\n",
            "==========\n",
            "행함이 없어도 불경건한 자를 의롭다 하시는 그분을 믿는 사람에게는 그의 믿음이 의로 여겨지느니라.,0\n",
            "0.0028648937586694956\n",
            "==========\n",
            "짱깨들 말하는 거임? 짱깨국이 무상의료라고?,1\n",
            "0.8125138878822327\n",
            "==========\n",
            "빡대가리들에게 방법을 가르쳐주시면 ㅠㅜ,1\n",
            "0.007387776859104633\n",
            "==========\n",
            "누가 뭐래냐?,0\n",
            "0.5854476094245911\n",
            "==========\n",
            "시발 정작 지네들 자식은 몸쓰는일 안시킬거면서 개지랄떠네 ㅋㅋㅋ,1\n",
            "0.006770510692149401\n",
            "==========\n",
            "용접협회 무시하지 마라. 저기 현장 고수및 용접에 관한 전문지식 가진 대학 교수 학자들 모임이다. 파워력 쎄다.,0\n",
            "0.0003719658125191927\n",
            "==========\n",
            "너도 해,0\n",
            "0.9686318039894104\n",
            "==========\n",
            "안하는 애들도 결국 학업에 흥미를 못 느꼈다는거니까,0\n",
            "0.08898022770881653\n",
            "==========\n",
            "니들 틀딱들 닭빨고 진빨고 중국빨고 그때그때 빠는새끼들임 닭이 친중하면 중국도 빨고 오성홍기절하고 아님? 억울하면 논리적으로 반박을 해 ㅋ,1\n",
            "0.9780762791633606\n",
            "==========\n",
            "그냥 홀딩하세요,0\n",
            "0.9805361032485962\n",
            "==========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij-RibXNLPF8",
        "outputId": "5ab2a86e-4d7c-4c4b-936e-f96a7285761a"
      },
      "source": [
        "count = 50\n",
        "\n",
        "with open(unlabeled_path2, \"r\") as f:\n",
        "  line = f.readline()\n",
        "  while True:\n",
        "    if count < 0: break\n",
        "    line = f.readline()\n",
        "\n",
        "    sent = predict_sentiment(model, tokenizer, line)\n",
        "    if sent > 0.95:\n",
        "      count -= 1\n",
        "      print(line, end=\"\")\n",
        "      print(predict_sentiment(model, tokenizer, line))\n",
        "      print(\"==========\")"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "좌배 까는건 ㅇㅂ,1\n",
            "0.9953380823135376\n",
            "==========\n",
            "731부대의 후예라 그런지 가학적인 아이디어는 세계최고임 이래서 애교만 떨어도 돈 벌리는 한국에 기를 써서 진출하려고 하지조센남자들은 또 이쁜여자만 보면 사족을 못쓰며 공주대접해주는 놈들이니,1\n",
            "0.962875485420227\n",
            "==========\n",
            "재앙이한건햇노,1\n",
            "0.9991575479507446\n",
            "==========\n",
            "ㅋㅋ ㅇㅈ 저런거에 앉아어 감전사 당할 수도,0\n",
            "0.9796949625015259\n",
            "==========\n",
            "군대에서 여군이 필요한가,0\n",
            "0.992216944694519\n",
            "==========\n",
            "사형 예지!,0\n",
            "0.999182403087616\n",
            "==========\n",
            "흑종원 ㅋㅋㅋ,0\n",
            "0.9727607369422913\n",
            "==========\n",
            "호주에서는 남자들이 동물보다 못한존재라던데ㅋㅋ,0\n",
            "0.9981912970542908\n",
            "==========\n",
            "너도 해,0\n",
            "0.9686318039894104\n",
            "==========\n",
            "니들 틀딱들 닭빨고 진빨고 중국빨고 그때그때 빠는새끼들임 닭이 친중하면 중국도 빨고 오성홍기절하고 아님? 억울하면 논리적으로 반박을 해 ㅋ,1\n",
            "0.9780762791633606\n",
            "==========\n",
            "그냥 홀딩하세요,0\n",
            "0.9805361032485962\n",
            "==========\n",
            "오마쥬가 뭔진 앎?,0\n",
            "0.9797841310501099\n",
            "==========\n",
            "쓰레기들은 휴지통으로,0\n",
            "0.9589219689369202\n",
            "==========\n",
            "앞머리 좀 자르던가 ㅅㅂ,1\n",
            "0.9995286464691162\n",
            "==========\n",
            "개찐따 답네 ㅋㅋㅋ,1\n",
            "0.999032735824585\n",
            "==========\n",
            "오이 오이 아부네,0\n",
            "0.9989733695983887\n",
            "==========\n",
            "이봐요 미친놈씨,1\n",
            "0.999839186668396\n",
            "==========\n",
            "이게 여자다,0\n",
            "0.9976119995117188\n",
            "==========\n",
            "키 170 27살 따먹은여자 23명 ㅁㅌㅊ?,1\n",
            "0.999806821346283\n",
            "==========\n",
            "극혐이노 ㅅㅂ ㅋㅋㅋ,1\n",
            "0.9958179593086243\n",
            "==========\n",
            "공지이잉 ㅅㅂㅋㅋㅋ,1\n",
            "0.9931545257568359\n",
            "==========\n",
            "ㅋㅋㅋ ㄹㅇ,0\n",
            "0.9909341335296631\n",
            "==========\n",
            "전라남도 안정권 홍어새끼 좆이나 빠는새끼가 가세연을 까노 ㅋㅋㅋ,1\n",
            "0.9654722809791565\n",
            "==========\n",
            "강사도 누구나 함 주둥이만있으면,1\n",
            "0.9699535369873047\n",
            "==========\n",
            "운지햐라,1\n",
            "0.9862536191940308\n",
            "==========\n",
            "거기서는 남자들이 디엠보내고 따먹음 ㅇㅇ 너 얼굴이 1차적 공략법이지 다른 방도는 없음 걸레들이 외모 더 따짐,1\n",
            "0.9996340274810791\n",
            "==========\n",
            "틀딱이네 --- 먹을 나이 됐다,1\n",
            "0.9932054281234741\n",
            "==========\n",
            "법이 ㅡㅡ 와일노,0\n",
            "0.9957285523414612\n",
            "==========\n",
            "남편이 스시남이더만,1\n",
            "0.9980390667915344\n",
            "==========\n",
            "잘 해봐라,0\n",
            "0.9989186525344849\n",
            "==========\n",
            "미친 짱깨년이 양키스 비니쓰고다니네 ㅋㅋㅋ,1\n",
            "0.9995900988578796\n",
            "==========\n",
            "\"저거 남자쪽에서도 저렇게 적게 받는건, 매달 나가는 돈 아니까 저렇게 적게 받는 경우가 많음.내 생각에 결혼하기전에 5000만원 정도는 비상금으로 가지고 있어야 함.그리고 결혼하고 생활비 다주더라도 가지고 있떤 5000만원 주식이든 펀드든 뭐든 넣어 불리면서 자산을 만들수 있어야 어디가도 기가 안죽음\",0\n",
            "0.9912844896316528\n",
            "==========\n",
            "카엔... 주인공보다 더 꼴림,0\n",
            "0.9711531400680542\n",
            "==========\n",
            "능지 병신들임 ㄹㅇ,1\n",
            "0.997786283493042\n",
            "==========\n",
            "이참에 그년 보지나 용접해 버리자,1\n",
            "0.9985942244529724\n",
            "==========\n",
            "자나깨나 정치생각 ㅋㅋㅋ,0\n",
            "0.9876783490180969\n",
            "==========\n",
            "내 댓글이 마운트 까는게 주 포인트는 아니긴 했는데나도 마운트 좋아함 하드워커에 에너지풀해서 ㅎㅎㅎ,0\n",
            "0.9540020823478699\n",
            "==========\n",
            "박사야!,0\n",
            "0.9700793623924255\n",
            "==========\n",
            "죽여버려야지 저런놈은,1\n",
            "0.9990693926811218\n",
            "==========\n",
            "이건 김성령이지,0\n",
            "0.9640139937400818\n",
            "==========\n",
            "복싱에선 여태 일본이 많이 쳐발렸다..,1\n",
            "0.9523830413818359\n",
            "==========\n",
            "좀 그만해라 씨발새끼들아ㅋ,1\n",
            "0.9802266359329224\n",
            "==========\n",
            "픽업아티스트다,0\n",
            "0.9539728760719299\n",
            "==========\n",
            "싸캐스틱이다 / /,0\n",
            "0.9776782989501953\n",
            "==========\n",
            "어렸을 때부터 키웠던 리트리버 키우고 일주일만 슬펐다 죽음에 너무 슬퍼하면 약해진다,0\n",
            "0.9666387438774109\n",
            "==========\n",
            "다들 ㅁㅈㅎ 난 ㅇㅂ,0\n",
            "0.9956637024879456\n",
            "==========\n",
            "\"도끼로 마빡을 걍.,...\",1\n",
            "0.9849027991294861\n",
            "==========\n",
            "입만 벌리면 구라.,1\n",
            "0.9918769598007202\n",
            "==========\n",
            "갓대중센세 모욕 ㅁㅈㅎ,0\n",
            "0.9998051524162292\n",
            "==========\n",
            "\"1주일 안으로 여자가 답 주긴 할텐데,, 안될 가능성이 높음\",0\n",
            "0.9996267557144165\n",
            "==========\n",
            "취하네요 ㅎㅎ,0\n",
            "0.9981366395950317\n",
            "==========\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}